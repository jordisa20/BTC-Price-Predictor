{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b69a87",
   "metadata": {},
   "source": [
    "# Bitcoin Price Prediction using AI Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12fd2b",
   "metadata": {},
   "source": [
    "### Elastic Net • XGBoost • LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c9810",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eb996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Misc\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d6588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, tensorflow as tf\n",
    "\n",
    "# Results deterministic\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a0f9c",
   "metadata": {},
   "source": [
    "## Load & Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12e7a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4009, 113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>daily_return_pct</th>\n",
       "      <th>weekly_return_pct</th>\n",
       "      <th>monthly_return_pct</th>\n",
       "      <th>yearly_return_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>high_volume_breakout</th>\n",
       "      <th>golden_cross</th>\n",
       "      <th>death_cross</th>\n",
       "      <th>breakout_20d_high</th>\n",
       "      <th>breakdown_20d_low</th>\n",
       "      <th>rsi_overbought</th>\n",
       "      <th>rsi_oversold</th>\n",
       "      <th>rsi_divergence</th>\n",
       "      <th>macd_bullish_cross</th>\n",
       "      <th>macd_bearish_cross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "      <td>-7.192558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "      <td>-6.984265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "      <td>3.573492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "      <td>-2.465854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        open        high         low       close    volume  \\\n",
       "0  2014-09-17  465.864014  468.174011  452.421997  457.334015  21056800   \n",
       "1  2014-09-18  456.859985  456.859985  413.104004  424.440002  34483200   \n",
       "2  2014-09-19  424.102997  427.834991  384.532013  394.795990  37919700   \n",
       "3  2014-09-20  394.673004  423.295990  389.882996  408.903992  36863600   \n",
       "4  2014-09-21  408.084991  412.425995  393.181000  398.821014  26580100   \n",
       "\n",
       "   daily_return_pct  weekly_return_pct  monthly_return_pct  yearly_return_pct  \\\n",
       "0               NaN                NaN                 NaN                NaN   \n",
       "1         -7.192558                NaN                 NaN                NaN   \n",
       "2         -6.984265                NaN                 NaN                NaN   \n",
       "3          3.573492                NaN                 NaN                NaN   \n",
       "4         -2.465854                NaN                 NaN                NaN   \n",
       "\n",
       "   ...  high_volume_breakout  golden_cross  death_cross  breakout_20d_high  \\\n",
       "0  ...                 False         False        False              False   \n",
       "1  ...                 False         False        False              False   \n",
       "2  ...                 False         False        False              False   \n",
       "3  ...                 False         False        False              False   \n",
       "4  ...                 False         False        False              False   \n",
       "\n",
       "   breakdown_20d_low  rsi_overbought  rsi_oversold  rsi_divergence  \\\n",
       "0              False           False         False           False   \n",
       "1              False           False          True           False   \n",
       "2              False           False          True           False   \n",
       "3              False           False          True           False   \n",
       "4              False           False          True           False   \n",
       "\n",
       "   macd_bullish_cross  macd_bearish_cross  \n",
       "0               False               False  \n",
       "1               False                True  \n",
       "2               False               False  \n",
       "3               False               False  \n",
       "4               False               False  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Minec\\Desktop\\BTC-Price-Predictor\\data\\BTC_USD_COMPLETE_ANALYSIS_20250907_220628.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3cbc7",
   "metadata": {},
   "source": [
    "## Preprocessing & Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ba0819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 109\n",
      "Total samples: 4008\n",
      "Train size:    2805\n",
      "Val size:      601\n",
      "Test size:     602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minec\\AppData\\Local\\Temp\\ipykernel_30080\\1627349610.py:16: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "# Convert Date column to datetime and sort by date\n",
    "if \"Date\" in data.columns:\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data = data.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# next-day close price\n",
    "#    target_close_1d = tomorrow's close\n",
    "data[\"target_close_1d\"] = data[\"close\"].shift(-1)\n",
    "\n",
    "# Drop the last row \n",
    "data = data.dropna(subset=[\"target_close_1d\"]).reset_index(drop=True)\n",
    "\n",
    "# Handle missing values in features \n",
    "data = data.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "# feature matrix X and target vector y\n",
    "#    - target_close_1d (our label)\n",
    "#    - close (today's close, to avoid leaking exact target)\n",
    "\n",
    "drop_cols = [\"target_close_1d\", \"close\"]\n",
    "\n",
    "numeric_cols = data.select_dtypes(include=[np.number, bool]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in drop_cols]\n",
    "\n",
    "X = data[feature_cols].astype(float)\n",
    "y = data[\"target_close_1d\"].astype(float)\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "\n",
    "# Time-based split: 70% train, 15% val, 15% test\n",
    "n = len(data)\n",
    "train_end = int(0.7 * n)\n",
    "val_end = int(0.85 * n)\n",
    "\n",
    "X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "X_val,   y_val   = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "X_test,  y_test  = X.iloc[val_end:], y.iloc[val_end:]\n",
    "\n",
    "print(\"Total samples:\", n)\n",
    "print(\"Train size:   \", len(X_train))\n",
    "print(\"Val size:     \", len(X_val))\n",
    "print(\"Test size:    \", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019c165",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7598cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression evaluation: MAE, RMSE, R^2\n",
    "def evaluate_regression(model_name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R^2  :\", r2)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "# Directional accuracy \n",
    "def directional_accuracy(y_true, y_pred, prev_close):\n",
    "    \"\"\"\n",
    "    y_true: actual next-day close\n",
    "    y_pred: predicted next-day close\n",
    "    prev_close: today's closing price (used to determine trend direction)\n",
    "    \"\"\"\n",
    "    true_up = (y_true.values > prev_close.values)\n",
    "    pred_up = (y_pred > prev_close.values)\n",
    "    return (true_up == pred_up).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81492668",
   "metadata": {},
   "source": [
    "## Prepare Previous-Day Close (for Trend Direction Evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b8d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_close_test length: 602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3406    41796.269531\n",
       "3407    42511.968750\n",
       "3408    43154.945312\n",
       "3409    42742.652344\n",
       "3410    41262.058594\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prev_close_test = today's closing price for each test row\n",
    "# (so we can compare if price goes up or down tomorrow)\n",
    "\n",
    "prev_close_test = data[\"close\"].iloc[val_end:]  # same index as X_test and y_test\n",
    "\n",
    "print(\"prev_close_test length:\", len(prev_close_test))\n",
    "prev_close_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b668e02",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8a239",
   "metadata": {},
   "source": [
    "# Model 1: Elastic Net (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e579bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elastic Net (Train)\n",
      "MAE : 449.5690405348561\n",
      "RMSE: 872.1607634299481\n",
      "R^2  : 0.9972482444064095\n",
      "\n",
      "Elastic Net (Val)\n",
      "MAE : 643.9576894190614\n",
      "RMSE: 888.484251499903\n",
      "R^2  : 0.9839602756555353\n",
      "\n",
      "Elastic Net (Test)\n",
      "MAE : 2024.2160887430566\n",
      "RMSE: 2638.840340527955\n",
      "R^2  : 0.9849025795658468\n",
      "\n",
      "Elastic Net Directional Accuracy (Test): 0.5149501661129569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minec\\Desktop\\BTC-Price-Predictor\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+09, tolerance: 7.754e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net baseline model\n",
    "elasticnet = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", ElasticNet(\n",
    "        alpha=0.1,        # regularization strength\n",
    "        l1_ratio=0.5,     # mix between L1 (Lasso) and L2 (Ridge)\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "elasticnet.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_en = elasticnet.predict(X_train)\n",
    "y_val_pred_en   = elasticnet.predict(X_val)\n",
    "y_test_pred_en  = elasticnet.predict(X_test)\n",
    "\n",
    "# Evaluate on train / val / test\n",
    "en_train_metrics = evaluate_regression(\"Elastic Net (Train)\", y_train, y_train_pred_en)\n",
    "en_val_metrics   = evaluate_regression(\"Elastic Net (Val)\",   y_val,   y_val_pred_en)\n",
    "en_test_metrics  = evaluate_regression(\"Elastic Net (Test)\",  y_test,  y_test_pred_en)\n",
    "\n",
    "# Directional accuracy on test set\n",
    "da_en_test = directional_accuracy(y_test, y_test_pred_en, prev_close_test)\n",
    "print(\"\\nElastic Net Directional Accuracy (Test):\", da_en_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94c902",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22145ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost (Train)\n",
      "MAE : 42.64179542255911\n",
      "RMSE: 62.7469355517178\n",
      "R^2  : 0.9999857569890134\n",
      "\n",
      "XGBoost (Val)\n",
      "MAE : 3133.6983738040767\n",
      "RMSE: 3902.853428192537\n",
      "R^2  : 0.6904991008658152\n",
      "\n",
      "XGBoost (Test)\n",
      "MAE : 21902.597253945183\n",
      "RMSE: 29145.79980908726\n",
      "R^2  : -0.8417406571045369\n",
      "\n",
      "XGBoost Directional Accuracy (Test): 0.4867109634551495\n"
     ]
    }
   ],
   "source": [
    "# XGBoost regression model\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=500,        # number of trees\n",
    "    max_depth=6,             # tree depth\n",
    "    learning_rate=0.05,      # step size shrinkage\n",
    "    subsample=0.8,           # row sampling\n",
    "    colsample_bytree=0.8,    # feature sampling\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1                \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb = xgb.predict(X_train)\n",
    "y_val_pred_xgb   = xgb.predict(X_val)\n",
    "y_test_pred_xgb  = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate on train / val / test\n",
    "xgb_train_metrics = evaluate_regression(\"XGBoost (Train)\", y_train, y_train_pred_xgb)\n",
    "xgb_val_metrics   = evaluate_regression(\"XGBoost (Val)\",   y_val,   y_val_pred_xgb)\n",
    "xgb_test_metrics  = evaluate_regression(\"XGBoost (Test)\",  y_test,  y_test_pred_xgb)\n",
    "\n",
    "# Directional accuracy on test set\n",
    "da_xgb_test = directional_accuracy(y_test, y_test_pred_xgb, prev_close_test)\n",
    "print(\"\\nXGBoost Directional Accuracy (Test):\", da_xgb_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee64c6c",
   "metadata": {},
   "source": [
    "## Model 2b: Tuned XGBoost (Reduced Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7078b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost TUNED (Train)\n",
      "MAE : 275.2477161971855\n",
      "RMSE: 553.5128965920338\n",
      "R^2  : 0.9988916619154208\n",
      "\n",
      "XGBoost TUNED (Val)\n",
      "MAE : 3189.9058827735025\n",
      "RMSE: 4025.610933848621\n",
      "R^2  : 0.6707232779067269\n",
      "\n",
      "XGBoost TUNED (Test)\n",
      "MAE : 21052.46699802741\n",
      "RMSE: 28466.284644385174\n",
      "R^2  : -0.7568638053826788\n",
      "\n",
      "XGBoost TUNED Directional Accuracy (Test): 0.5066445182724253\n"
     ]
    }
   ],
   "source": [
    "# Tuned XGBoost model with stronger regularization to reduce overfitting\n",
    "\n",
    "xgb_tuned = XGBRegressor(\n",
    "    n_estimators=200,        # fewer trees than before\n",
    "    max_depth=3,             # shallower trees (less complex)\n",
    "    learning_rate=0.05,      # same step size\n",
    "    subsample=0.8,           # row sampling\n",
    "    colsample_bytree=0.8,    # feature sampling\n",
    "    reg_lambda=2.0,          # L2 regularization (stronger)\n",
    "    reg_alpha=1.0,           # L1 regularization\n",
    "    min_child_weight=5,      # require more samples in leaves\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the tuned model\n",
    "xgb_tuned.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb_tuned = xgb_tuned.predict(X_train)\n",
    "y_val_pred_xgb_tuned   = xgb_tuned.predict(X_val)\n",
    "y_test_pred_xgb_tuned  = xgb_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate on train / val / test\n",
    "xgb_tuned_train_metrics = evaluate_regression(\"XGBoost TUNED (Train)\", y_train, y_train_pred_xgb_tuned)\n",
    "xgb_tuned_val_metrics   = evaluate_regression(\"XGBoost TUNED (Val)\",   y_val,   y_val_pred_xgb_tuned)\n",
    "xgb_tuned_test_metrics  = evaluate_regression(\"XGBoost TUNED (Test)\",  y_test,  y_test_pred_xgb_tuned)\n",
    "\n",
    "# Directional accuracy on test set\n",
    "da_xgb_tuned_test = directional_accuracy(y_test, y_test_pred_xgb_tuned, prev_close_test)\n",
    "print(\"\\nXGBoost TUNED Directional Accuracy (Test):\", da_xgb_tuned_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26582327",
   "metadata": {},
   "source": [
    "Deep/complex models don't automatically outperform simpler linear models on highly volatile financial time-series. The data isn't stationary, it's full of noise, the market keeps hitting random structural breaks, so even increased model complexity doesn't guarantee better predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c1b3b",
   "metadata": {},
   "source": [
    "## 8. Model 3: LSTM (Long Short-Term Memory Network)\n",
    "\n",
    "The shape needed: [ samples , time_steps , features ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5b008",
   "metadata": {},
   "source": [
    "### Create Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e705546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM data shapes:\n",
      "Train: (2775, 30, 109)\n",
      "Val:   (601, 30, 109)\n",
      "Test:  (602, 30, 109)\n"
     ]
    }
   ],
   "source": [
    "# number of past days LSTM will look at\n",
    "window_size = 30\n",
    "\n",
    "# Scale features before sequence creation\n",
    "scaler_lstm = StandardScaler()\n",
    "X_scaled = scaler_lstm.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "\n",
    "# Function to convert time-series into sequences\n",
    "def make_sequences(X_df, y_series, window):\n",
    "    X_seq, y_seq, prev_close_seq = [], [], []\n",
    "    closes = data[\"close\"].values  # to compute trend later\n",
    "\n",
    "    for i in range(window, len(X_df)):\n",
    "        X_seq.append(X_df.iloc[i-window:i].values)  # window_size × features\n",
    "        y_seq.append(y_series.iloc[i])              # next-day target\n",
    "        prev_close_seq.append(closes[i-1])          # today's close (to determine direction)\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq), np.array(prev_close_seq)\n",
    "\n",
    "# Create sequences\n",
    "X_seq, y_seq, prev_close_all = make_sequences(X_scaled_df, y, window_size)\n",
    "\n",
    "# Fix alignment with earlier splits\n",
    "offset = window_size\n",
    "train_end_seq = train_end - offset\n",
    "val_end_seq   = val_end - offset\n",
    "\n",
    "X_train_lstm = X_seq[:train_end_seq]\n",
    "y_train_lstm = y_seq[:train_end_seq]\n",
    "\n",
    "X_val_lstm   = X_seq[train_end_seq:val_end_seq]\n",
    "y_val_lstm   = y_seq[train_end_seq:val_end_seq]\n",
    "\n",
    "X_test_lstm  = X_seq[val_end_seq:]\n",
    "y_test_lstm  = y_seq[val_end_seq:]\n",
    "prev_close_test_lstm = prev_close_all[val_end_seq:]\n",
    "\n",
    "print(\"LSTM data shapes:\")\n",
    "print(\"Train:\", X_train_lstm.shape)\n",
    "print(\"Val:  \", X_val_lstm.shape)\n",
    "print(\"Test: \", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d9fba",
   "metadata": {},
   "source": [
    "### Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85883a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minec\\Desktop\\BTC-Price-Predictor\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 430933408.0000 - mae: 12372.0029 - val_loss: 735184704.0000 - val_mae: 26190.1914\n",
      "Epoch 2/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430809664.0000 - mae: 12366.5459 - val_loss: 735088768.0000 - val_mae: 26188.0273\n",
      "Epoch 3/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430732928.0000 - mae: 12363.4395 - val_loss: 735004864.0000 - val_mae: 26186.1523\n",
      "Epoch 4/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430660448.0000 - mae: 12360.4609 - val_loss: 734933440.0000 - val_mae: 26184.5020\n",
      "Epoch 5/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430583840.0000 - mae: 12357.5117 - val_loss: 734864192.0000 - val_mae: 26182.8848\n",
      "Epoch 6/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430516832.0000 - mae: 12354.6621 - val_loss: 734790912.0000 - val_mae: 26181.2070\n",
      "Epoch 7/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430445824.0000 - mae: 12351.7998 - val_loss: 734715456.0000 - val_mae: 26179.4863\n",
      "Epoch 8/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430376448.0000 - mae: 12349.0020 - val_loss: 734640128.0000 - val_mae: 26177.7793\n",
      "Epoch 9/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430306816.0000 - mae: 12346.1836 - val_loss: 734565248.0000 - val_mae: 26176.0762\n",
      "Epoch 10/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430238112.0000 - mae: 12343.4463 - val_loss: 734489152.0000 - val_mae: 26174.3555\n",
      "Epoch 11/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430167200.0000 - mae: 12340.5898 - val_loss: 734413248.0000 - val_mae: 26172.6387\n",
      "Epoch 12/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 430102880.0000 - mae: 12337.7080 - val_loss: 734338048.0000 - val_mae: 26170.9355\n",
      "Epoch 13/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 430030432.0000 - mae: 12334.9277 - val_loss: 734262976.0000 - val_mae: 26169.2383\n",
      "Epoch 14/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 429964896.0000 - mae: 12332.2002 - val_loss: 734186880.0000 - val_mae: 26167.5156\n",
      "Epoch 15/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 429895296.0000 - mae: 12329.4844 - val_loss: 734110912.0000 - val_mae: 26165.8047\n",
      "Epoch 16/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429823616.0000 - mae: 12326.5557 - val_loss: 734033216.0000 - val_mae: 26164.0586\n",
      "Epoch 17/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429753056.0000 - mae: 12323.7842 - val_loss: 733957184.0000 - val_mae: 26162.3457\n",
      "Epoch 18/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429689504.0000 - mae: 12321.0352 - val_loss: 733880640.0000 - val_mae: 26160.6191\n",
      "Epoch 19/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429615936.0000 - mae: 12318.2168 - val_loss: 733804736.0000 - val_mae: 26158.9082\n",
      "Epoch 20/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429550304.0000 - mae: 12315.5000 - val_loss: 733727424.0000 - val_mae: 26157.1699\n",
      "Epoch 21/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429492000.0000 - mae: 12312.9971 - val_loss: 733651008.0000 - val_mae: 26155.4473\n",
      "Epoch 22/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429411424.0000 - mae: 12310.0469 - val_loss: 733574208.0000 - val_mae: 26153.7246\n",
      "Epoch 23/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429350080.0000 - mae: 12307.0342 - val_loss: 733497024.0000 - val_mae: 26151.9844\n",
      "Epoch 24/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429275712.0000 - mae: 12304.4697 - val_loss: 733419776.0000 - val_mae: 26150.2461\n",
      "Epoch 25/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429208096.0000 - mae: 12301.5742 - val_loss: 733342720.0000 - val_mae: 26148.5156\n",
      "Epoch 26/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429148064.0000 - mae: 12298.8916 - val_loss: 733266048.0000 - val_mae: 26146.7930\n",
      "Epoch 27/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 429072192.0000 - mae: 12296.2158 - val_loss: 733189184.0000 - val_mae: 26145.0586\n",
      "Epoch 28/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 428994080.0000 - mae: 12293.4111 - val_loss: 733111232.0000 - val_mae: 26143.3086\n",
      "Epoch 29/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 428940224.0000 - mae: 12290.6924 - val_loss: 733033216.0000 - val_mae: 26141.5586\n",
      "Epoch 30/30\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 428874528.0000 - mae: 12287.8428 - val_loss: 732956480.0000 - val_mae: 26139.8340\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(window_size, X_train_lstm.shape[-1])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)  # predict next-day closing price\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = lstm_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_data=(X_val_lstm, y_val_lstm),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090fc47f",
   "metadata": {},
   "source": [
    "### Evaluate LSTM on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ae62f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "LSTM (Train)\n",
      "MAE : 12286.388182628734\n",
      "RMSE: 20708.297013352305\n",
      "R^2  : -0.5432427489763698\n",
      "\n",
      "LSTM (Val)\n",
      "MAE : 26139.83485783654\n",
      "RMSE: 27073.169163924944\n",
      "R^2  : -13.892774909004565\n",
      "\n",
      "LSTM (Test)\n",
      "MAE : 81040.27938665682\n",
      "RMSE: 83838.96831308278\n",
      "R^2  : -14.239417638153979\n",
      "\n",
      "LSTM Directional Accuracy (Test): 0.4700996677740864\n"
     ]
    }
   ],
   "source": [
    "# Predictions for LSTM\n",
    "y_train_pred_lstm = lstm_model.predict(X_train_lstm).flatten()\n",
    "y_val_pred_lstm   = lstm_model.predict(X_val_lstm).flatten()\n",
    "y_test_pred_lstm  = lstm_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "# Evaluate on train / val / test\n",
    "lstm_train_metrics = evaluate_regression(\"LSTM (Train)\", y_train_lstm, y_train_pred_lstm)\n",
    "lstm_val_metrics   = evaluate_regression(\"LSTM (Val)\",   y_val_lstm,   y_val_pred_lstm)\n",
    "lstm_test_metrics  = evaluate_regression(\"LSTM (Test)\",  y_test_lstm,  y_test_pred_lstm)\n",
    "\n",
    "# Directional accuracy on test set\n",
    "da_lstm_test = directional_accuracy(\n",
    "    pd.Series(y_test_lstm),\n",
    "    y_test_pred_lstm,\n",
    "    pd.Series(prev_close_test_lstm)\n",
    ")\n",
    "print(\"\\nLSTM Directional Accuracy (Test):\", da_lstm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d1932",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26156c",
   "metadata": {},
   "source": [
    "For predicting Bitcoin closing price and trend, simpler linear models (Elastic Net) generalized better than deep learning (LSTM) and ensemble trees (XGBoost), because the crypto market is extremely volatile and driven by external non-numerical events that models cannot learn from price history alone.\n",
    "\n",
    "- Elastic Net: Was most stable\n",
    "- XGBoost: Overfits price jumps\n",
    "- LSTM: Underfits trend patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51196e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
